<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>xbo&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Linux服务器最大支撑多少TCP连结TCP连接四元组：源IP、源端口、目的IP、目的端口，理论上一个服务，例如Nginx，其接受的连接的目的IP和目的端口是固定的，故可以建立2^32^（IP数）*2^16^（端口数）个链接。 进程每打开一个文件（Linux下一切皆文件）都会消耗一定的内存资源，Linux基于安全考虑，对可打开的文件描述符的数量有系统级、用户级、进程级的限制（分别是当前系统、指定用">
<meta property="og:type" content="article">
<meta property="og:title" content="xbo&#39;s Blog">
<meta property="og:url" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="xbo&#39;s Blog">
<meta property="og:description" content="Linux服务器最大支撑多少TCP连结TCP连接四元组：源IP、源端口、目的IP、目的端口，理论上一个服务，例如Nginx，其接受的连接的目的IP和目的端口是固定的，故可以建立2^32^（IP数）*2^16^（端口数）个链接。 进程每打开一个文件（Linux下一切皆文件）都会消耗一定的内存资源，Linux基于安全考虑，对可打开的文件描述符的数量有系统级、用户级、进程级的限制（分别是当前系统、指定用">
<meta property="og:locale">
<meta property="og:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/1df6c196ed6c08f700b253e2039da1e3.png">
<meta property="og:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/4de8505e72cdbd67db7cc4ba91ad14a2.png">
<meta property="og:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/image-20210104150151546.png">
<meta property="og:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/640">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/9lFFFiaKpEr8Pnej5HSUaPCia1zguc4Kbh0KM76luxZCsRicZBsaLrx9snP0acox4yKbIGg3mDmCfwwB9yMSamwfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_jpg/iaIdQfEric9TyvNCUZ5V9vVVL9KicIukrtXUBfGpPL3Ngoe2os48MDXAu2FnGTQcdGFaqXRh6puSialDbX5SlPkSqw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="og:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%B4%E6%8A%A4.png">
<meta property="article:published_time" content="2021-03-24T06:02:27.589Z">
<meta property="article:modified_time" content="2021-01-05T08:19:24.632Z">
<meta property="article:author" content="xbo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/1df6c196ed6c08f700b253e2039da1e3.png">
  
    <link rel="alternate" href="/atom.xml" title="xbo's Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">xbo&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-微信公众号笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2021-03-24T06:02:27.589Z" itemprop="datePublished">2021-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="Linux服务器最大支撑多少TCP连结"><a href="#Linux服务器最大支撑多少TCP连结" class="headerlink" title="Linux服务器最大支撑多少TCP连结"></a>Linux服务器最大支撑多少TCP连结</h3><p>TCP连接四元组：源IP、源端口、目的IP、目的端口，理论上一个服务，例如Nginx，其接受的连接的目的IP和目的端口是固定的，故可以建立2^32^（IP数）*2^16^（端口数）个链接。</p>
<p>进程每打开一个文件（Linux下一切皆文件）都会消耗一定的内存资源，Linux基于安全考虑，对可打开的文件描述符的数量有系统级、用户级、进程级的限制（分别是当前系统、指定用户、单个进程可打开的最大数量）。</p>
<p>###以太网最小帧为什么是64字节</p>
<p>早期以太网使用集线器构建星型网络，集线器会将一个端口收到的数据包泛红出去，为了避免数据冲突，网卡使用CSMA/CD载波监听多路访问/冲突避免协议，在发送数据时会检测信道上是否已有主机在发送数据，如果有则终止发送。</p>
<p>假设A向B发送数据，在数据到达B的前极小一段时间$t-\delta$($\delta\rightarrow0$,t为单程端到端传播时延)内，B检测到信道空闲，于是发送数据，此时发送碰撞，经过t时间后A检测到发送碰撞，此次发送失败。如果A超过2t时间都没有检测到碰撞，则A发送的数据一定不会发生碰撞，因此为了使A检测到碰撞，需要使A单次发送数据的时长需要超过2t，这个时长又称为争用期或碰撞事件。</p>
<p>电磁波在1km电缆中的传播时延约为5us，10Mbps以太网允许最大连接长度是2500米，最多经过4个中继器，因此最大往返时间为50us，考虑到中继器的转发时延等，实际争用期确定为51.2us。10Mbps*51.2us=64Bytes，这就是以太网帧的最小长度，又称为以太网时隙。如果某主机发送完一个帧的64字节仍无冲突，则以后也不会再发生冲突了，称此主机捕获了信道。由于信道是所有主机共享，为了避免单一主机占用信道时间过长，规定了以太网帧的最大帧长为1500。</p>
<h3 id="Linux网络接收包过程"><a href="#Linux网络接收包过程" class="headerlink" title="Linux网络接收包过程"></a>Linux网络接收包过程</h3><p>Linux实现的是链路层、网络层和传输层，链路层协议靠网卡驱动实现，内核协议栈来实现网络层和传输层，内核对应用层提供socket接口来供用户进程访问。</p>
<p>用户执行完recvfrom调用后，用户进程就通过系统调用进入到内核态工作，如果接收队列没有数据，进程就进入睡眠状态被操作系统挂起。</p>
<p>网口收到数据后，网卡驱动会以DMA的方式将接收到的帧写到内存里的环形缓冲队列RingBuffer，再向CPU发起硬中断（给CPU的相关引脚上触发一个电压变化），CPU再调用网卡驱动注册的中断处理函数，由于该硬中断优先级过高，并且网络模块的处理过程比较复杂和耗时，如果在中断函数中完成所有处理将过度占用CPU，因此Linux将中断处理函数分为上半部分和下半部分，上半部分只进行简单工作，快速处理后释放CPU，剩下的绝大部分工作都放到下半部分，下半部分采用的是软中断（通过改变内存中的一个变量值以通知软中断处理程序），软中断将调用网卡注册的poll函数开始从RingBuffer内轮询收包，交由内核的各级协议栈开始处理，处理完的数据data被放置到socket的接收队列中，然后由内核唤醒用户进程，进入用户态。</p>
<p>收包过程的CPU开销：1. 用户进程通过系统调用陷入内核态的开销， 2. CPU响应网口硬中断的CPU开销， 3. 软中断中各级协议栈处理数据包的CPU开销。</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>Linux系统中一切皆文件，因此许多操作都可以归类与读写操作，零拷贝技术是为了提高读写性能。</p>
<p>读操作：</p>
<ol>
<li><p>仅CPU方式</p>
<p>应用程序调用read()陷入内核态，CPU向磁盘控制器发起IO请求，磁盘控制器将数据放至磁盘缓冲区后向CPU发起IO中断，CPU将数据拷贝至内核缓冲区，再拷贝至用户缓冲区，read()调用返回，切换到用户态。</p>
</li>
<li><p>CPU&amp;DMA方式</p>
<p>相比于仅CPU方式，CPU向DMA控制器发起IO请求，由DMA控制器向磁盘发起IO请求，磁盘控制器将数据放至磁盘缓冲区后向DMA控制器发送完成信号，由DMA控制器将数据拷贝至内核缓冲区，再由CPU拷贝至用户缓冲区。</p>
</li>
</ol>
<p>写操作：</p>
<p>应用程序调用write()陷入内核态，CPU将用户缓冲区数据拷贝至内核缓冲区，再由CPU或DMA控制器将数据拷贝至socket缓冲区，完成拷贝，write()调用返回，切换到用户态。</p>
<p>零拷贝技术：</p>
<ol>
<li><p>mmap+write</p>
<p>mmap是Linux提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享。减少了一次用户态和内核态之间的CPU拷贝，但是在内核空间内仍然有一次CPU拷贝。</p>
</li>
<li><p>sendfile</p>
<p>sendfile在两个文件描述符之间拷贝数据，拷贝在内核态中完成，因此相比于read+write和mmap+write减少了一次系统调用（少了两次状态切换），用于数据不经过用户缓冲区，因此数据无法被修改。</p>
</li>
<li><p>sendfile+DMA</p>
<p>sendfile将内核空间缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到socket缓冲区中，DMA控制器根据socket缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，从而省去了内核空间中仅剩的1次CPU拷贝。</p>
</li>
</ol>
<h3 id="操作系统内存管理"><a href="#操作系统内存管理" class="headerlink" title="操作系统内存管理"></a>操作系统内存管理</h3><p>程序直接使用物理内存会使所有进程的安全性得不到保证。</p>
<p>地址空间：进程可用于寻址内存的一套地址集合，每个进程都有一套自己的地址空间，各个进程的地址空间是独立的。进程所使用的内存地址是虚拟地址，操作系统将不同进程的虚拟地址和内存中不同的物理地址映射起来，对进程而言是透明的。</p>
<p>地址空间建立：</p>
<ol>
<li><p>直接将每个进程的地址空间分别映射到物理内存的不同部分，操作系统为每个进程提供一个基址和界限，为此CPU中配置了基址寄存器和界限寄存器。</p>
<p>如果程序太大，超过内存容量，可以采用手动覆盖技术：把程序按照自身逻辑结构，划分成多个功能相互独立的程序模块，常用的模块常驻内存，不常用的模块平时放到外存中，在需要时加载到内存中，不同时执行的模块可以共享同一块内存区域。</p>
<p>如果程序太多，超过内存容量，可以采用交换技术，将暂时不能运行的程序换出到外存中，以接收新的进程，或将外存中的进程换入到内存中。</p>
</li>
<li><p>使用虚拟内存</p>
<p>确保每个程序拥有自己的地址空间，地址空间被分成多个块，同时物理内存空间也分成多个块，块大小和虚拟地址空间的块大小一致，操作系统会自动将虚拟地址空间映射到真实物理地址空间，程序所关注的只是虚拟内存，请求的也是虚拟内存，其实真正使用的是物理内存。</p>
<p>虚拟内存技术一般是在页式管理的基础上实现</p>
<p>  在装入程序时，不必将其全部装入到内存，而只需将当前需要执行的部分页面装入到内存，就可让程序开始执行；</p>
<p>  在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页异常）。则由处理器通知操作系统将相应的页面调入到内存，更新页表，然后继续执行程序；</p>
<p>  操作系统将内存中暂时不使用的页面调出保存在外存上，从而腾出更多空闲空间存放将要装入的程序以及将要调入的页面。 </p>
</li>
</ol>
<p>虚拟内存映射到物理内存由CPU中的内存管理单元MMU完成，虚拟内存不直接送到内存总线，而是先给MMU。</p>
<p>分页内存管理：</p>
<p>将虚拟地址空间和物理地址空间分成若干个连续且固定大小的块，虚拟地址空间中的块就被称为<strong>页Page</strong>，物理地址空间这些块被称为<strong>页框</strong>。页面太大容易产生空间浪费，页面太小会导致页表占用空间过大，大多数系统都使用4KB作为页的大小。</p>
<p>MMU通过<strong>页表</strong>将虚拟地址转换为物理地址。虚拟地址分成两部分（页号和偏移量），页号作为页表的索引，MMU通过页表找到了页号对应的页框的物理基地址，页框的物理基地址+偏移量就是实际访问的物理地址。</p>
<p>页表结构：</p>
<p>| 页号 | 内存块号 | 状态位 | 访问字段 | 修改位 | 外存地址 |</p>
<p>TLB：</p>
<p>每条指令执行基本都会进行多次页表查询，依据程序局部性原理（时间局部性：对一条执行/数据的的执行/访问都集中在一个较短时间内， 空间局部性：当前执行/访问的指令/数据都集中在一个较小区域内），通过在CPU中加入专门存放程序最常访问的页表项的缓存，提高页表查询映射的速度，这个缓存称为 TLB（<em>Translation Lookaside Buffer</em>，转换检测缓冲区） ，通常称为页表缓存、转址旁路缓存、快表等。MMU每次进行虚拟地址转换时，首先去TLB中查找，找到了有效的物理页框则直接返回，如果没有找到则进行正常的页表访问。</p>
<p>多级页表：</p>
<p>32/64位操作系统有很大的虚拟地址空间，其对应的页表会非常大，同时每个进程都有自己的页表，会导致页表占用过大的内存空间，解决方法是使用多级页表。以一个32位虚拟地址的二级页表为例，将32位虚拟地址划分为10位的PT1域，10位的PT2域，以及12位的offset域，当一个虚拟地址被送入MMU时，MMU首先提取PT1域并把其值作为访问第一级页表的索引，之后提取PT2域把把其值作为访问第二级页表的索引，之后再根据offset找到对应的页框号。</p>
<p>32位的虚拟地址空间下：每个页面4KB，且每条页表项占4B：</p>
<p><strong>一级页表</strong>：进程需要1M个页表项（4GB / 4KB = 1M, 2^20个页表项），即页表（每个进程都有一个页表）占用4MB（1M * 4B = 4MB）的内存空间。</p>
<p><strong>二级页表</strong>：一级页表映射4MB（2^22）、二级页表映射4KB，则需要1K个一级页表项（4GB / 4MB = 1K, 2^10个一级页表项）、每个一级页表项对应1K个二级页表项（4MB / 4KB = 1K），这样页表占用4.004MB（1K * 4B + 1K * 1K * 4B = 4.004MB）的内存空间。</p>
<p>每个进程都有4GB的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到4GB，因此不必要映射不可能用到的空间，也就是说，一级页表覆盖了整个4GB虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。假设只有20%的一级页表项被用到了，那么页表占用的内存空间就只有0.804MB （1K*4B+0.2*1K*1K*4B=0.804MB）。由于页表承担的职责是将虚拟地址翻译成物理地址，页表一定要覆盖全部虚拟地址空间，因此未分级的页表不能通过减少映射 未使用空间的 表项来减少内存占用。</p>
<p>缺页中断：</p>
<p>缺页中断就是要访问的页不在主存中，需要操作系统将页调入主存后再进行访问，此时会暂时停止指令的执行，产生一个页不存在的异常，对应的异常处理程序就会从选择一页调入到内存，调入内存后之前的异常指令就可以继续执行。</p>
<p>缺页会带来巨大的软件开销：决定置换哪个或哪些驻留页、交换页所需要的IO操作、调度另一个进程导致的进程切换等。</p>
<p>缺页中断处理过程：如果内存中有空闲的物理页框，则直接将外存中所需要访问的页装入该物理页框中，否则根据某种页面置换算法选择一个将被替换的物理页框，将该页框内的页写入外存，再将外存中所需要访问的页装入该物理页框中，然后重新运行被中断的指令。</p>
<p>页面读取策略：</p>
<ul>
<li>请求分页：只有当访问到某页中的一个单元时才将该页读入内存。</li>
<li>预先分页：基于局部性原理和存储设备特性（一次读取多个连续页比连续读取多个页更快，省略了寻道时间和延迟），一次读取多个连续的页。</li>
</ul>
<p>驻留集管理：驻留集即驻留在内存中的页面构成的集合，</p>
<ul>
<li>固定分配策略：在进程加载时，为一个进程在内存中分配固定数量的页框。</li>
<li>可变分配策略：分配给一个进程的页框在该进程的生命周期中不断变化，若进程的缺页率一直比较高，说明在该进程中局部性原理表现比较弱，应该给它多分配一些页框以减少缺页率，否则可以减少分配的页框数。</li>
</ul>
<p>清除策略：</p>
<ul>
<li>请求式清除：只有当一页被选择用于置换时才被写回外存。</li>
<li>预约式清除：就已修改的多页在需要使用它们所占据的页框之前成批写回外存。</li>
</ul>
<p>页面分配：</p>
<p>为了提升向内存中读入和从内存中写出页的效率。</p>
<p>伙伴系统 用于把连续的页映射到连续的页框中。 Linux内核维护一系列大小固定的连续页框组，一组可以包含1、2、4、8、16或32个页框，当一页在内存中被分配或被解除分配时，可用的页框组使用伙伴算法来分裂或合并。</p>
<p>页面置换算法：</p>
<p>页面置换算法的目的是尽可能减少页面的换入换出次数（缺页中断次数），尽量把未来不再使用的或短期内较少使用的页面换出，通常在程序局部性原理指导下依据过去的统计数据来进行预测。</p>
<ol>
<li><p>最优置换算法（OPT, Optimal）</p>
<p>选择距离下一次访问时间最久（即在内存中即将等待最长时间）的页面。最佳置换算法可以保证最低的缺页率，但是实际上，只有进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面的访问序列，因此该算法无法实现。</p>
</li>
<li><p>先进先出置换算法（FIFO）</p>
<p>选择最早进入内存的页面，FIFO算法与进程实际运行时的规律不适应。因为最先进入的页面也有可能最经常被访问，因此该算法性能差。</p>
</li>
<li><p>最近最少使用置换算法（LRU, Least Recently Used）</p>
<p>选择最近最少使用（即最近最久未被使用）的页面，在每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中t最大的页面，即最近最久未使用。该算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大。</p>
</li>
<li><p>时钟置换算法（CLOCK，NRU）</p>
<p>为内存中每个页面设置一个<strong>访问位</strong>，再将内存中的页面都通过链接指针链接成一个循环队列，并使用另一个表指针指向最老的页面。当某个页被访问时，将其访问位置1.当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出，并将表指针指向下一个页面；如果是1，则将其访问位置0，再继续检查下一个页面，若第一轮扫描中所有的页面都是1，则将这些页面的访问位全部置为0后，再进行第二轮扫描。</p>
<p>由于该算法循环地检查各页面的情况，故称为 CLOCK 算法，又称为最近未用( Not Recently Used, NRU )算法。</p>
</li>
<li><p>改进型的时钟置换算法</p>
<p>简单的时钟置换算法仅考虑到了一个页面最近是否被访问过。事实上，如果淘汰的页面没有被修改过，就不需要执行I/O操作写回外存，只有淘汰的页面被修改过时，才需要写回外存。因此，除了考虑一个页面最近有没有被访问过之外，操作系统还需要考虑页面有没有被修改过。改进型时钟置换算法的算法思想<strong>：</strong>在其他在条件相同时，应该优先淘汰没有被修改过的页面，从而来避免I/O操作。用（访问位，修改位）的形式表示各页面的状态。如（1,1）表示一个页面近期被访问过，且被修改过。</p>
<p>将所有可能被置换的页面排成一个循环队列</p>
<p>  第一轮：从表指针位置开始扫描第一个（0,0）的页用于替换（淘汰的是<strong>最近没有访问且没有修改</strong>的页面），本轮扫描不修改任何标志位。<br>  第二轮：若第一轮扫描失败，则重新扫描，查找第一个（0,1）的页用于替换（淘汰的是<strong>最近没有访问但修改</strong>的页面）。本轮将所有扫描的过的页访问位设为0。<br>  第三轮：若第二轮扫描失败，则重新扫描，查找第一个（0,0）的页用于替换（淘汰的是<strong>最近访问但没有修改</strong>的页面）。本轮扫描不修改任何标志位。<br>  第四轮：若第三轮扫描失败，则重新扫描，查找第一个（0,1）的页用于替换（淘汰的是<strong>最近访问且修改</strong>的页面）。</p>
<p>该算法开销小，性能也不错</p>
</li>
<li><p>最不常用算法</p>
</li>
</ol>
<p>  为每个页面设置一个计数器，被访问时，该页面的访问计数器加1，在需要淘汰时，选择计数器值最小的那个页面。但当一个页面在进程的初始阶段大量使用但是随后不再使用时，由于它具有一个大的计数，它会仍久保留在内存中，一种解决方案是，定期地将计数右移 1 位，以形成指数衰减的平均使用计数。</p>
<p>  该算法的实现是昂贵的，并且它们不能很好地近似 OPT 置换。</p>
<p>分段内存管理：</p>
<p>8086CPU时期，程序访问内存时使用的是真实物理地址，为了方便多道程序并发执行，需要支持对各个程序进行重定位。通过分段机制，程序中使用的地址由段基址+段内偏移量组成，操作系统通过更改段基址，就可进行重定位。而且8086CPU的地址线宽度是20位，可寻址范围可以达到1MB，但是它们的寄存器都是16位，直接使用1个16位寄存器不可能访存达到1MB，因此引入了段，引入了段寄存器，段寄存器左移4位+偏移量就可以生成20位的地址，从而达到1MB的寻址范围。</p>
<p>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），这相当于屏蔽了处理器中的段式内存管理，段只被用于访问控制和内存保护。</p>
<p>Linux中的虚拟地址空间的内部又被分为<strong>内核空间（内核态下可访问）和用户空间（进程在用户态下可访问</strong>两部分，每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址关联的都是相同的物理内存，从而当进程切换到内核态后可以很方便地访问内核空间内存。</p>
<p>32位系统的内核空间占用高位1G（0xC0000000-0xFFFFFFFF)，用户空间占用低位3G（0x0-0xC0000000)，64位系统的内核空间占用高位128T（0xFFFF800000000000-0xFFFFFFFFFFFFFFFF)，用户空间占用低位128T（0x0-0x00007FFFFFFFF000)，其余中间部分是未定义空间。</p>
<p>用户空间内存中，从低到高依次是程序文件段、已初始化数据段、未初始化数据段、堆段（包括动态分配的内存，从低地址开始向上增长）、文件映射段（包括动态库、共享内存等）、栈段（包括局部变量和函数调用的上下文等）。堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 <code>malloc()</code> 或者 <code>mmap()</code> ，就可以分别在堆和文件映射段动态分配内存。</p>
<h3 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h3><p>I/O一般指磁盘I/O和网络I/O。</p>
<p>I/O多路复用是指用一个或少量线程处理多个TCP连接。</p>
<p>I/O模型：阻塞、非阻塞、同步、非同步。</p>
<p>进程模型：单进程、多进程、多线程。</p>
<p>一次IO分为两个阶段：等待数据（数据可能来自其他应用程序或者网络）、拷贝数据（将就绪的数据拷贝到应用程序工作区）</p>
<p>同步和非同步的概念描述的是用户线程和内核的交互方式，同步是指用户线程发起I/O请求后需要等待或轮询内核I/O操作，异步是指用户线程发起I/O请求后仍继续执行，当内核I/O操作完成后通知用户线程，或者调用用户线程注册的回调函数。</p>
<p>阻塞和非阻塞的概念描述的是用户线程调用内核I/O操作的方式，阻塞是指I/O操作需要彻底完成后才能返回用户空间，非阻塞是指I/O操作被调用后立即返回给用户一个状态值，而无需等待I/O操作彻底完成。</p>
<p>传输层、网络层、链路层由系统内核负责，内核处理所有通信细节，包括收发数据、等待确认、给无序到达的数据排序等。</p>
<p>同步阻塞IO：用户线程通过调用系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接受的数据拷贝到用户空间，完成read操作。整个IO请求过程，用户线程都是被阻塞的，对CPU利用率不够。JAVA传统的BIO（Blocking IO）属于此种方式。</p>
<p>传统的服务器端同步阻塞I/O处理（也就是BIO，Blocking I/O）的经典编程模型，在读取输入流或者写入输出流时，在读、写动作完成之前，线程会一直阻塞。在这种模型下使用多线程的主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的。</p>
<p>这个模型严重依赖于线程，但线程是很”贵”的资源，主要表现在：</p>
<ol>
<li><strong>线程的创建和销毁成本很高</strong>，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。</li>
<li>线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，占用的内存将非常惊人。</li>
<li><strong>线程的切换成本是很高的</strong>。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。</li>
<li><strong>容易造成锯齿状的系统负载</strong>。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高而且外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。</li>
</ol>
<p>同步非阻塞IO：在同步基础上将socket设置为NONBLOCK，用户线程在发起IO请求后立即返回，此时并未读到任何数据，用户线程需要不断的轮询内核，直到数据到达后才能真正读到数据。不断的轮询消耗了大量的CPU资源，实际用处不大。JAVA的NIO（Non-blocking IO/New IO）属于此种方式。</p>
<p>多路复用IO：也称为事件驱动IO，由单个线程处理多个IO连接。</p>
<p>信号驱动式IO：用户线程发起IO请求时注册一个信号函数，请求立即返回，操作系统底层则处于等待状态（等待数据就绪），直到数据就绪，然后通过信号通知主调程序，主调程序才去调用系统函数recvfrom()完成IO操作。属于非阻塞式IO，针对于一个IO的完成过程。</p>
<p>异步IO：将整个IO操作（包括等待数据就绪，复制数据到应用程序工作空间）全都交给操作系统完成。数据就绪后操作系统将数据拷贝进应用程序运行空间之后，操作系统再通知应用程序，这个过程中应用程序不需要阻塞。</p>
<p>IO多路复用使用的系统调用select/poll/epoll，目的在于同时处理多个连接，解决线程/进程数量过多对服务器开销造成的压力，而不是更快，在连接数不大的情况下，性能不一定优于多线程+阻塞IO。</p>
<p>select/poll/epoll都是阻塞式IO，调用这些I/O多路复用函数时如果任何一个需要监视的文件描述符都不可读或者可写那么进程会被阻塞暂停执行，直到有文件描述符可读或者可写才继续运行。</p>
<p>I/O多路复用就是使用一个进程监视多个描述符（socket），一旦某个描述符就绪（读就绪或写就绪），就通知程序进行相应的读写操作了，</p>
<p>LINUX中一切皆文件，比如设备、网络连接、进程间通信管道等，所有的I/O操作都可以通过文件读写来实现，一般有打开文件open、改变读写位置seek、文件读写read/write、关闭文件close等。文件描述符（file description）唯一标识了一个文件。</p>
<p>select：</p>
<p>将需要监控的文件描述符集合通过参数传递给select，调用select后函数会阻塞，直到有描述符就绪（有数据读、写、或异常）或超时，函数返回所有文件描述符集合。当select函数返回后，通过遍历文件描述符集合找到就绪的描述符。</p>
<p>可监控的文件描述符集合不能超过1024个，无法实现高并发；需要遍历文件描述符数组，轮询的开销会随着文件描述符数量的增加而线性增加，效率低；涉及到大量文件描述符数组在内核空间和用户空间之间的拷贝，而不论这些文件描述符是否就绪，性能消耗大；</p>
<p>poll：</p>
<p>取消了可监控文件描述符最大数量限制。</p>
<p>epoll：</p>
<p>使用事件驱动，避免了轮询查看可读写事件。</p>
<p>epoll在阻塞监听描述符就绪状态时，仅会返回已经就绪的文件描述符集合，而无需再遍历集合。epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知，这样IO的效率不会随着监视fd的数量的增长而下降。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_create</span><span class="params">(<span class="keyword">int</span> size)</span> <span class="comment">//创建一个epoll的句柄，size是最大的描述符监听数。size并不会真正限制epolll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议值。</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_ctl</span><span class="params">(<span class="keyword">int</span> epfd, <span class="keyword">int</span> op, <span class="keyword">int</span> fd, struct epoll_event *event)</span> <span class="comment">//对指定描述符的监听事件执行指定的Op操作，epfd：是epoll_create()的返回值，fd：是需要监听的文件描述符，epoll_event：是告诉内核需要监听什么事，op：表示操作，有三个宏定义，分别是添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, struct epoll_event * events, <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout)</span> <span class="comment">//等待epfd上的io事件，最多返回maxevents个事件, 该方法与Java NIO的select()方法类似，maxevents的值不能超过epoll_create中的参数size的大小，也就是说，size的大小也间接限制了epoll的线程一次会批量处理几个IO事件。</span></span></span><br></pre></td></tr></table></figure>



<p>###Reactor模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The reactor design pattern is an event handling pattern for handling service requests delivered concurrently to a service handler by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to the associated request handlers</span><br></pre></td></tr></table></figure>

<ol>
<li>Reactor模式是一种事件驱动模式</li>
<li>一个或多个输入是同时交付的</li>
<li>服务控制器会分离到达的多个请求并同步的分发给相关的处理器进行处理</li>
</ol>
<p><img src="%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/1df6c196ed6c08f700b253e2039da1e3.png" alt="reactor模型.png"></p>
<p><img src="%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/4de8505e72cdbd67db7cc4ba91ad14a2.png" alt="reactor模式.png"></p>
<ul>
<li>Synchronous Event Demutiplexer是同步事件分离器，是IO多路服用技术实现的关键，主要任务是监听系统的Handlers中事件的发生，监听的过程是阻塞等待的</li>
<li>Handle是句柄，即操作系统管理的资源</li>
<li>Dispatcher是分发器，负责根据Event的类型来调用EventHandler</li>
<li>EventHandler是事件处理器，每个事件处理器会关联一个Handle</li>
</ul>
<p>流程如下所述：</p>
<ul>
<li>初始化Dispatcher</li>
<li>注册EventHandler到Dispatcher中，每个EventHandler包含对相应Handle的引用，从而建立Handle到EventHandler的映射</li>
<li>启动Event Loop。在Event Loop中，调用select()方法,Synchronous Event Demultiplexer阻塞等待Event发生</li>
<li>当某个或某些Handle的Event发生后，select()方法返回，Dispatcher根据返回的Event找到注册的EventHandler，并回调该EventHandler的handle_event()方法</li>
<li>在EventHandler的handle_event()方法中还可以向Dispatcher中注册新的EventHandler，用来处理下一个Event</li>
</ul>
<p>主从Reactor多线程模型</p>
<p>Reactor分成两部分：</p>
<ol>
<li>mainReactor负责监听server socket，用来处理网络IO连接建立操作，将建立的socketChannel指定注册给subReactor。</li>
<li>subReactor主要做和建立起来的socket做数据交互和事件业务处理操作。通常，subReactor个数上可与CPU个数等同。</li>
</ol>
<p><img src="%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/image-20210104150151546.png" alt="image-20210104150151546"></p>
<p>消息处理流程：</p>
<ol>
<li>从主线程池中随机选择一个Reactor线程作为acceptor线程，用于绑定监听端口，接收客户端连接</li>
<li>acceptor线程接收客户端连接请求之后创建新的SocketChannel，将其注册到主线程池的其它Reactor线程上，由其负责接入认证、IP黑白名单过滤、握手等操作</li>
<li>步骤2完成之后，业务层的链路正式建立，将SocketChannel从主线程池的Reactor线程的多路复用器上摘除，重新注册到Sub线程池的线程上，并创建一个Handler用于处理各种连接事件</li>
<li>当有新的事件发生时，SubReactor会调用连接对应的Handler进行响应</li>
<li>Handler通过Read读取数据后，会分发给后面的Worker线程池进行业务处理</li>
<li>Worker线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给Handler进行处理</li>
<li>Handler收到响应结果后通过Send将响应结果返回给Client</li>
</ol>
<p>NIO</p>
<ul>
<li>NIO是Java SDK提供的基于Reactor模式的非阻塞IO工作模式的实现</li>
<li>NIO与IO的主要区别包括：</li>
</ul>
<table>
<thead>
<tr>
<th>NIO</th>
<th>IO</th>
</tr>
</thead>
<tbody><tr>
<td>面向缓冲</td>
<td>面向流</td>
</tr>
<tr>
<td>非阻塞IO</td>
<td>阻塞 IO</td>
</tr>
</tbody></table>
<p>面向缓冲是NIO与传统IO最大的区别，传统的IO是基于字节的，所有的IO都被看作是单个子节的移动，而NIO是基于块的，一个块则由多个字节组成，从简单的原理上看，NIO的性能提升主要来源于每一次IO操作都能尽可能的读写更多的字节，而更直接的提升是得益于NIO使用的IO读写结构Channel和Buffer非常贴近操作系统执行IO的方式:通道和缓冲器。简单的理解就是越接近操作系统底层，越快速。</p>
<p>NIO对Reactor模型组件的实现</p>
<ol>
<li>Selector : Synchronous Event Demultiplexer</li>
<li>SelectKey : Event</li>
<li>SocketChannel : Handle</li>
<li>(Handlers write by yourself) : EventHandler</li>
</ol>
<h3 id="高性能开发要点"><a href="#高性能开发要点" class="headerlink" title="高性能开发要点"></a>高性能开发要点</h3><p>CPU：提升主频（加快指令执行速度）、使用多级缓存（加快CPU读取数据速度）、多核技术、超线程技术、多线程技术、无锁编程技术、协程技术。</p>
<p>内存：提升主频与容量、降低读取时延、换页/交换技术、TLB、大页内存技术、NUMA感知（CPU核需要通过内存总线访问内存，NUMA架构把CPU核心划分不同的分组，各自使用独立的内存访问总线，减少内存总线的竞争，提高内存访问速度，降低访问延迟）。</p>
<p>I/O：非阻塞IO、I/O多路复用、异步I/O、DMA、零拷贝、线程池。</p>
<p>算法架构：分布式集群、负载均衡、数据库索引、数据库缓存中间件、CDN。</p>
<ul>
<li>I/O优化：零拷贝技术</li>
<li>I/O优化：多路复用技术</li>
<li>线程池技术</li>
<li>无锁编程技术</li>
<li>进程间通信技术</li>
<li>RPC &amp;&amp; 序列化技术</li>
<li>数据库索引技术</li>
<li>缓存技术 &amp;&amp; 布隆过滤器</li>
<li>全文搜索技术</li>
<li>负载均衡技术</li>
</ul>
<h3 id="进程和线程相关问题"><a href="#进程和线程相关问题" class="headerlink" title="进程和线程相关问题"></a>进程和线程相关问题</h3><p>什么是进程？</p>
<p>标准定义：进程是一个具有一定独立功能的程序在一个数据集合上依次动态执行的过程。进程是一个正在执行程序的实例，包括程序计数器、寄存器和程序变量的当前值。简单来说进程就是一个程序的执行流程，内部保存程序运行所需的资源。</p>
<p>在操作系统中可以有多个进程在运行，可对于CPU来说，同一时刻，一个CPU只能运行一个进程，但在某一时间段内，CPU将这一时间段拆分成更短的时间片，CPU不停的在各个进程间快速切换，这就给人一种并行的错觉，像CPU可以同时运行多个进程一样，这就是伪并行。</p>
<p>进程和程序有什么联系？</p>
<p>一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。</p>
<p>程序是产生进程的基础</p>
<p>程序的每次运行产生不同的进程</p>
<p>进程是程序功能的体现</p>
<p>通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序</p>
<p>进程和程序有什么区别？</p>
<p>进程是动态的，程序是静态的：程序是有序代码的集合，进程是程序的执行。</p>
<p>进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可长久保存。</p>
<p>进程和程序的组成不同：进程的组成包括程序、数据和进程控制块（进程状态信息）。</p>
<p>进程如何创建？</p>
<p><strong>系统初始化</strong>：当启动操作系统时，通常会创建很多进程，有些是同用户交互并替他们完成工作的前台进程，其它的都是后台进程，后台进程和特定用户没有关系，但也提供某些专门的功能，例如接收邮件等，这种功能的进程也称为守护进程。计划任务是个典型的守护进程，它每分钟运行一次来检查是否有工作需要它完成。如果有工作要做，它就会完成此工作，然后进入休眠状态，直到下一次检查时刻的到来。</p>
<p><strong>正在运行的程序执行了创建进程的系统调用</strong>。</p>
<p><strong>用户请求创建一个新进程</strong>。</p>
<p><strong>一个批处理作业的初始化</strong>：这种情形不常见，仅在大型机的批处理系统中应用，用户在这种系统中提交批处理作业，在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。</p>
<p>进程为何终止？</p>
<p><strong>正常退出</strong>：进程完成了工作正常终止，UNIX中退出进程的系统调用是exit。</p>
<p><strong>出错退出</strong>：进程发现了错误而退出。可以看如下代码：</p>
<p><strong>严重错误</strong>：进程发生了严重的错误而不得不退出，通常是程序的错误导致，例如执行了一条非法指令，引用不存在的内存，或者除数是0等，出现这些错误时进程默认会退出。而有些时候如果用户想自行处理某种类型的错误，发生不同类型错误时进程会收到不同类型的信号，用户注册处理不同信号的函数即可。</p>
<p><strong>被其它进程杀死</strong>：其它进程执行kill系统调用通知操作系统杀死某个进程。</p>
<p>操作系统如何进行进程管理？</p>
<p>一个数据结构：进程控制块（PCB），操作系统为每个进程都维护一个PCB，用来保存与该进程有关的各种状态信息。进程可以抽象理解为一个PCB，PCB是进程存在的唯一标志，操作系统用PCB来描述进程的基本情况以及运行变化的过程，进程的任何状态变化都会通过PCB来体现。</p>
<p>PCB包含进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其它在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未中断过一样。</p>
<p>中断向量是指中断服务程序的入口地址。一个进程在执行过程中可能会被中断无数次，但是每次中断后，被中断的进程都要返回到与中断发生前完全相同的状态。</p>
<p>进程控制块中存储了什么信息？</p>
<p><strong>进程标识信息</strong>：如本进程的标识，本进程的父进程标识，用户标识等。</p>
<p><strong>处理机状态信息保护区</strong>：用于保存进程的运行现场信息：</p>
<p>  用户可见寄存器：用户程序可以使用的数据，地址等寄存器</p>
<p>  控制和状态寄存器：程序计数器，程序状态字</p>
<p>  栈指针：过程调用、系统调用、中断处理和返回时需要用到它</p>
<p><strong>进程控制信息</strong>：</p>
<p>  调度和状态信息：用于操作系统调度进程使用</p>
<p>  进程间通信信息：为支持进程间与通信相关的各种标识、信号、信件等，这些信息存在接收方的进程控制块中</p>
<p>  存储管理信息：包含有指向本进程映像存储空间的数据结构进程所用资源：说明由进程打开使用的系统资源，如打开的文件等</p>
<p>  有关数据结构连接信息：进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB</p>
<p>进程如何进行生命周期管理？</p>
<p><strong>进程创建</strong>：创建进程有三个主要事件：</p>
<p>  系统初始化</p>
<p>  用户请求创建一个新进程</p>
<p>  一个正在运行的进程执行创建进程的系统调用</p>
<p><strong>进程运行</strong>：内核根据调度策略选择一个就绪的进程，让它占用CPU并运行。</p>
<p><strong>进程等待</strong>：在以下情况下进程会等待（阻塞）：</p>
<p>  请求并等待系统服务，</p>
<p>  无法马上完成启动某种操作，</p>
<p>  无法马上完成需要的数据没有到达。</p>
<p>注意：进程只能自己阻塞自己，因为只有进程自身才能知道何时需要等待某种事件的发生。</p>
<p><strong>进程唤醒</strong>：进程只能被别的进程或操作系统唤醒，唤醒进程的原因有：</p>
<p>  被阻塞进程需要的资源可被满足</p>
<p>  被阻塞进程等待的事件到达</p>
<p>  将该进程的PCB插入到就绪队列</p>
<p><strong>进程结束</strong>：在以下四种情况下进程会结束：自愿型正常退出、自愿型错误退出、强制型致命错误退出、强制型被其它进程杀死退出</p>
<p>进程都有什么状态？</p>
<p>不同系统设置的进程状态是不同的，多数系统中的进程在生命结束前有三种基本状态，进程只会处于三种基本状态之一：</p>
<p><strong>运行状态</strong>：进程正在CPU上运行时就处在运行状态，该时刻进程时钟占用着CPU；</p>
<p><strong>就绪状态</strong>：进程已经获得了除CPU之外的一切所需资源，一旦得到CPU就可以运行；就绪态中的进程其实可以运行，但因为其它进程正在占用着CPU而暂时停止运行；</p>
<p><strong>等待状态（阻塞状态）</strong>：进程正在等待某一事件而暂停运行，等待某个资源或者等待输入输出完成。除非某种外部事件发生，否则阻塞态的进程不能运行；</p>
<p><img src="%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/640" alt="图片"></p>
<p>什么是进程挂起？为什么会出现进程挂起？</p>
<p>进程挂起就是为了合理且充分的利用系统资源，把一个进程从内存转到外存。进程在挂起状态时，意味着进程没有占用内存空间，处在挂起状态的进程映射在磁盘上。进程挂起通常有两种状态：</p>
<p>  阻塞挂起状态：进程在外存并等待某事件的出现；</p>
<p>  就绪挂起状态：进程在外存，但只要进入内存即可运行。</p>
<p>进程挂起可能有以下几种情况：</p>
<p>  <strong>阻塞到阻塞挂起</strong>：没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种转换，以提交新进程或运行就绪进程；</p>
<p>  <strong>就绪到就绪挂起</strong>：当有高优先级阻塞进程或低优先级就绪进程时，系统会选择挂起低优先级就绪进程；</p>
<p>  <strong>运行到就绪挂起</strong>：对于抢占式分时系统，当有高优先级阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态；</p>
<p>  <strong>阻塞挂起到就绪挂起</strong>：当有阻塞挂起进程有相关事件出现时，系统会把阻塞挂起进程转换为就绪挂起进程。</p>
<p>  <strong>有进程挂起那就有进程解挂：指一个进程从外存转到内存，相关状态有</strong>：</p>
<p>  <strong>就绪挂起到就绪</strong>：没有就绪进程或就绪挂起进程优先级高于就绪进程时，就会进行这种转换；</p>
<p>  <strong>阻塞挂起到阻塞</strong>：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起进程转换为阻塞进程。</p>
<p>####什么是进程调度？操作系统对于进程调度都有什么策略？</p>
<p>当系统中有多个进程同时竞争CPU，如果只有一个CPU可用，那同一时刻只会有一个进程处于运行状态，操作系统必须要选择下一个要运行的是哪个进程，在操作系统中，完成选择工作的这部分称为调度程序，该程序使用的算法称作<strong>调度算法</strong>。</p>
<p><strong>什么时候进行调度</strong>？</p>
<p>系统调用创建一个新进程后，需要决定是运行父进程还是运行子进程</p>
<p>一个进程退出时需要做出调度决策，需要决定下一个运行的是哪个进程</p>
<p>当一个进程阻塞在I/O和信号量或者由于其它原因阻塞时，必须选择另一个进程运行</p>
<p>当一个I/O中断发生时，如果中断来自IO设备，而该设备现在完成了工作，某些被阻塞的等待该IO的进程就成为可运行的就绪进程了，是否让新就绪的进程运行，或者让中断发生时运行的进程继续运行，或者让某个其它进程运行，这就取决于调度程序的抉择了。</p>
<p><strong>调度算法可以分类：</strong></p>
<ul>
<li><p><strong>非抢占式调度算法</strong>：挑选一个进程，然后让该进程运行直至被阻塞，或者直到该进程自动释放CPU，即使该进程运行了若干个小时，它也不会被强迫挂起。这样做的结果是，在时钟中断发生时不会进行调度，在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。简单来说，调度程序必须等待事件结束。</p>
<p>非抢占方式引起进程调度的条件：</p>
<ul>
<li>进程执行结束，或发生某个事件而不能继续执行</li>
<li>正在运行的进程因有I/O请求而暂停执行</li>
<li>进程通信或同步过程中执行了某些原语操作（wait、block等）</li>
</ul>
</li>
<li><p><strong>抢占式调度算法</strong>：挑选一个进程，并且让该进程运行某个固定时段的最大值。如果在该时段结束时，该进程仍在运行，它就被挂起，而调度程序挑选另一个进程运行，进行抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便CPU控制返回给调度程序，如果没有可用的时钟，那么非抢占式调度就是唯一的选择。简单来说，就是当前运行的进程在事件没结束时就可以被换出，防止单一进程长时间独占CPU资源。</p>
</li>
</ul>
<p><strong>调度策略</strong>：</p>
<p>  不同系统环境下有不同的调度策略算法。调度算法也是有KPI的，对调度算法首先提的需求就是：</p>
<ul>
<li><p><strong>公平</strong>：调度算法需要给每个进程公平的CPU份额，相似的进程应该得到相似的服务，对一个进程给予较其它等价的进程更多的CPU时间是不公平的。</p>
</li>
<li><p><strong>执行力</strong>：每一个策略必须强制执行，需要保证规定的策略一定要被执行。</p>
</li>
<li><p><strong>平衡</strong>：需要保证系统的所有部分尽可能都忙碌</p>
</li>
</ul>
<p>但是因为不同的应用有不同的目标，不同的系统中，调度程序的优化也是不同的，大体可以分为三种环境：</p>
<ul>
<li><p>批处理系统</p>
<ul>
<li>批处理系统的管理者为了掌握系统的工作状态，主要关注三个指标：</li>
<li>吞吐量：是系统每小时完成的作业数量</li>
<li>周转时间：指从一个作业提交到完成的平均时间</li>
<li>CPU利用率：尽可能让CPU忙碌，但又不能过量</li>
</ul>
<p>调度算法：</p>
<ul>
<li><strong>先来先服务</strong>（FCFS/FIFO）：进程按照它们请求CPU的顺序来使用CPU，该算法最大的优点就是简单易于实现，但平均等待时间波动较大，时间短的任务可能排队排在了时间长的任务后面。</li>
<li><strong>最短执行时间进程优先</strong>：该调度算法是非抢占式的算法，每个进程执行期间不会被打断，每次都选择执行时间最短的进程来调度，但操作系统可能不知道进程具体的执行时间，所以该算法注定是基于预测性质的理想化算法，而且有违公平性，而且可能导致运行时间长的任务得不到调度。</li>
<li><strong>最短剩余时间优先</strong>：该调度算法是抢占式的算法，是最短进程优先的抢占版本，在进程运行期间，如果来了个更短时间的进程，那就转而去把CPU时间调度给这个更短时间的进程，它的缺点和最短进程优先算法类似。</li>
</ul>
</li>
<li><p>交互式系统</p>
<p>对于交互系统最重要的指标就是响应时间和均衡性：</p>
<ul>
<li><p>响应时间：一个请求被提交到产生第一次响应所花费的时间。</p>
</li>
<li><p>均衡性：减少平均响应时间的波动。需要符合固有期望和预期，</p>
</li>
</ul>
<p>调度算法：</p>
<ul>
<li><p><strong>轮转调度</strong>：基于时钟的抢占策略，每个进程被分配一个时间段，称为时间片，CPU根据周期性的时钟中断，在多个进程间快速切换，进程仅允许在时间片内运行，所有进程具有相同优先级。时间片太短会导致过多的进程切换，频繁的上下文切换会降低CPU效率，而如果时间片设的太长又可能对短的交互请求的响应时间变长。</p>
</li>
<li><p><strong>优先级调度</strong>：简单的轮转调度算法中默认每个进程具有相同优先级，在优先级调度算法中，每个优先级都有相应的队列，队列里面装着对应优先级的进程，首先在高优先级队列中进行轮转调度，当高优先级队列为空时，转而去低优先级队列中进行轮转调度，如果高优先级队列始终不为空，那么低优先级的进程很可能就会饥饿到很久不能被调度。</p>
</li>
<li><p><strong>多级反馈队列</strong>：多级队列算法与优先级调度算法不同，优先级算法中每个进程分配的是相同的时间片，而在多级队列算法中，不同队列中的进程分配给不同的时间片，当一个进程用完分配的时间片后就移动到下一个具有更多时间片的队列中，这样可以更好的避免上下文频繁切换。</p>
</li>
<li><p><strong>最短执行进程进程优先</strong>：交互式系统中应用最短进程优先算法其实是非常适合的，每次都选择执行时间最短的进程进行调度，这样可以使任务的响应时间最短，没有办法非常准确的在当前可运行进程中找出最短的进程，有一种办法就是根据进程过去的行为进行预测。</p>
</li>
<li><p><strong>保证调度</strong>：这种调度算法就是向用户做出明确的可行的性能保证，然后去实现它。一种很实际的可实现的保证就是确保N个用户中每个用户都获得CPU处理能力的1/N，类似的，保证N个进程中每个进程都获得1/N的CPU时间。</p>
</li>
<li><p><strong>彩票调度</strong>彩票调度算法基本思想是为进程提供各种资源（CPU时间）的彩票，一旦需要做出调度决策时，就随机抽出一张彩票，拥有该彩票的进程获得该资源，很明显，拥有彩票越多的进程，获得资源的可能性越大。</p>
</li>
<li><p><strong>公平分享调度</strong></p>
<p>上述调度算法考虑的都是单个用户下的进程池。在多用户系统中，用户关心的是构成应用程序的一组进程（而不是特定进程）如何执行。公平共享调度是基于进程组的调度策略。</p>
<p>每个用户被指定了某种类型的权值，该权值定义了用户对系统资源的共享，即用户占用的资源在所有可使用资源中的比例。</p>
<p>假设有系统两个用户，用户1启动了1个进程，用户2启动了9个进程，如果使用轮转调度算法，那么用户1将获得10%的CPU时间，用户2将获得90%的CPU时间。</p>
</li>
</ul>
</li>
<li><p>实时系统</p>
<p>实时系统最关键的指标是实时性：</p>
<ul>
<li>满足截止时间：需要在规定期限前完成作业；</li>
<li>可预测性：可预测性是指在系统运行的任何时刻，在任何情况下，实时系统的资源调配策略都能为争夺资源的任务合理的分配资源，使每个实时任务都能得到满足。</li>
</ul>
<p>调度算法分类：</p>
<ul>
<li><strong>硬实时</strong>：必须在规定期限之前完成工作，如果延迟则可能会发生灾难性或发生严重的后果；</li>
<li><strong>软实时</strong>：必须在规定期限之前完成工作，但如果偶尔延迟了，也可以容忍。</li>
</ul>
<p>调度算法：</p>
<ul>
<li><strong>单调速率调度</strong>：采用抢占式、静态优先级的策略，调度周期性任务。每个任务最开始都被配置好了优先级，当较低优先级的进程正在运行并且有较高优先级的进程可以运行时，较高优先级的进程将会抢占低优先级的进程。在进入系统时，每个周期性任务都会分配一个优先级，周期越短，优先级越高。这种策略的理由是：更频繁的需要CPU的任务应该被分配更高的优先级。</li>
<li><strong>最早截止时间调度</strong>：根据截止时间动态分配优先级，截止时间越早的进程优先级越高。该算法中，当一个进程可以运行时，它应该向操作系统通知截止时间，根据截止时间的早晚，系统会为该进程调整优先级，以便满足可运行进程的截止时间要求。它与单调速率调度算法的区别就是一个是静态优先级，一个是动态优先级。</li>
</ul>
</li>
</ul>
<p><strong>如何配置调度策略？</strong></p>
<p>调度算法有很多种，各有优缺点，操作系统自己很少能做出最优的选择，那么可以把选择权交给用户，由用户根据实际情况来选择适合的调度算法，这就叫策略与机制分离，调度机制位于内核，调度策略由用户进程决定，将调度算法以某种形式参数化，由用户进程来选择参数从而决定内核使用哪种调度算法。</p>
<p><strong>操作系统怎么完成进程调度？</strong></p>
<p>进程的每次变化都会有相应的状态，而操作系统维护了一组状态队列，表示系统中所有进程的当前状态；不同的状态和同一个状态的不同的优先级都有不同的队列，有就绪队列、阻塞队列等，每个进程的PCB都根据它的状态加入到相应的队列中，当一个进程的状态发生变化时，它的PCB会从一个状态队列中脱离出来加入到另一个状态队列。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/9lFFFiaKpEr8Pnej5HSUaPCia1zguc4Kbh0KM76luxZCsRicZBsaLrx9snP0acox4yKbIGg3mDmCfwwB9yMSamwfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<p>多处理器调度：</p>
<ul>
<li>负载分配：系统维护一个就绪线程的全局队列，每个处理器只要空闲就从队列中选择一个线程运行。</li>
<li>组调度：一组相关的线程按照一对一的原则，同时调度到一组处理器上运行。</li>
<li>专用处理器分配：把线程指定到特定处理器。每个程序在其执行过程中，都分配有一组处理器，处理器数量与程序中线程数量相等，即将每个线程都分配给一个专用处理器，直至程序结束。</li>
<li>动态调度：</li>
</ul>
<p>####什么是线程？</p>
<p>  线程是进程当中的一条执行流程，一个进程内可以有多个子执行流程，即线程。</p>
<h4 id="为什么使用线程？"><a href="#为什么使用线程？" class="headerlink" title="为什么使用线程？"></a>为什么使用线程？</h4><p>因为要并发编程，在许多情形中同时发生着许多活动，而某些活动有时候会被阻塞，通过将这些活动分解成可以准并行运行的多个顺序流程是必须的，而如果使用多进程方式进行并发编程，进程间的通信也很复杂，并且维护进程的系统开销较大：创建进程时分配资源建立PCB，撤销进程时回收资源撤销PCB，进程切换时保存当前进程的状态信息。所以为了使并发编程的开销尽量小，所以引入多线程编程，可以并发执行也可以共享相同的地址空间。并行实体拥有共享同一地址空间和所有可用数据的能力，这是多进程模型所不具备的能力。</p>
<p>使用线程有如下优点：</p>
<ul>
<li><p>可以多个线程存在于同一个进程中</p>
</li>
<li><p>各个线程之间可以并发的执行</p>
</li>
<li><p>各个线程之间可以共享地址空间和文件等资源</p>
</li>
<li><p>线程比进程更轻量级，创建线程撤销线程比创建撤销进程要快的多，在许多系统中，创建一个线程速度是创建一个进程速度的10-100倍。</p>
</li>
<li><p>如果多个线程是CPU密集型的，并不能很好的获得更好的性能，但如果多个线程是IO密集型的，线程存在着大量的计算和大量的IO处理，有多个线程允许这些活动彼此重叠进行，从而会加快整体程序的执行速度。</p>
</li>
</ul>
<p>但也有缺点：</p>
<ul>
<li><p>一旦一个线程崩溃，会导致其所属进程的所有线程崩溃。</p>
</li>
<li><p>由于各个线程共享相同的地址空间，那么读写数据可能会导致竞争关系，因此对同一块数据的读写需要采取某些同步机制来避免线程不安全问题。</p>
</li>
</ul>
<h4 id="什么时候用进程、线程？"><a href="#什么时候用进程、线程？" class="headerlink" title="什么时候用进程、线程？"></a>什么时候用进程、线程？</h4><ul>
<li><p>进程是资源分配单位，线程是CPU调度单位；</p>
</li>
<li><p>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</p>
</li>
<li><p>线程同样具有就绪阻塞和执行三种基本状态，同样具有状态之间的转换关系；</p>
</li>
<li><p>线程能减少并发执行的时间和空间开销：</p>
<ul>
<li>线程的创建时间比进程短</li>
<li>线程的终止时间比进程短</li>
<li>同一进程内的线程切换时间比进程短</li>
<li>由于同一进程的各线程间共享内存和文件资源，可直接进行不通过内核的通信</li>
</ul>
</li>
</ul>
<h4 id="线程是如何实现的？线程的实现可分为用户线程和内核线程："><a href="#线程是如何实现的？线程的实现可分为用户线程和内核线程：" class="headerlink" title="线程是如何实现的？线程的实现可分为用户线程和内核线程："></a>线程是如何实现的？线程的实现可分为用户线程和内核线程：</h4><p>  <strong>用户线程</strong>：在用户空间实现的线程机制，它不依赖于操作系统的内核，由一组用户级的线程库函数来完成线程的管理，包括进程的创建终止同步和调度等。</p>
<p>用户线程有如下优点：</p>
<ul>
<li><p>由于用户线程的维护由相应进程来完成（通过线程库函数），不需要操作系统内核了解内核了解用户线程的存在，可用于不支持线程技术的多进程操作系统。</p>
</li>
<li><p>每个进程都需要它自己私有的线程控制块列表，用来跟踪记录它的各个线程的状态信息（PC，栈指针，寄存器），TCB由线程库函数来维护；</p>
</li>
<li><p>用户线程的切换也是由线程库函数来完成，无需用户态/核心态切换，所以速度特别快；</p>
</li>
<li><p>允许每个进程拥有自定义的线程调度算法；</p>
</li>
</ul>
<p>但用户线程也有缺点：</p>
<ul>
<li><p>如果一个线程发起系统调用而阻塞，则整个进程在等待。</p>
</li>
<li><p>当一个线程开始运行后，除非它主动交出CPU的使用权，否则它所在进程当中的其它线程将无法运行；</p>
</li>
<li><p>由于时间片分配给进程，与其它进程比，在多线程执行时，每个线程得到的时间片较少。</p>
</li>
</ul>
<p><strong>内核线程</strong>：是指在操作系统的内核中实现的一种线程机制，由操作系统的内核来完成线程的创建终止和管理。</p>
<p>  在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息（PCB TCB）；</p>
<p>  线程的创建终止和切换都是通过系统调用内核函数的方式来进行，由内核来完成，因此系统开销较大；</p>
<p>  在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其它内核线程的运行；</p>
<p>  时间片分配给线程，多线程的进程获得更多CPU时间；</p>
<p>由于在内核中创建或撤销线程的代价比较大，某些系统采取复用的方式回收线程，当某个线程被撤销时，就把它标记不可运行，但是内核数据结构没有受到任何影响，如果后续又需要创建一个新线程时，就重新启动被标记为不可运行的旧线程，从而节省一些开销。</p>
<p><strong>轻量级进程</strong>：它是内核支持的用户线程模型，一个进程可以有多个轻量级进程，每个轻量级进程由一个单独的内核线程来支持。在Linux下是没有真正的线程的，它所谓的线程其实就是使用进程来实现的，就是所谓的轻量级进程，其实就是进程，都是通过clone接口调用创建的，只不过两者传递的参数不同，通过参数决定子进程和父进程共享的资源种类和数量，进而有了普通进程和轻量级进程的区别。</p>
<h4 id="什么是上下文切换？"><a href="#什么是上下文切换？" class="headerlink" title="什么是上下文切换？"></a>什么是上下文切换？</h4><p>上下文切换指的是操作系统停止当前运行线程（从运行状态改变成其它状态）并且调度其它线程（就绪态转变成运行状态）。操作系统必须在切换之前存储许多部分的线程上下文，必须能够在之后恢复它们。同时切换上下文这个过程必须快速，因为上下文切换操作是非常频繁的。</p>
<p>上下文指的是任务所有共享资源的工作现场，每一个共享资源都有一个工作现场，包括用于处理函数调用、局部变量分配以及工作现场保护的栈顶指针，和用于指令执行等功能的各种寄存器。</p>
<h4 id="进程间通信有几种方式？"><a href="#进程间通信有几种方式？" class="headerlink" title="进程间通信有几种方式？"></a>进程间通信有几种方式？</h4><p>由于各个进程不共享相同的地址空间，任何一个进程的全局变量在另一个进程中都不可见，所以如果想要在进程之间传递数据就需要通过内核，在内核中开辟出一块区域，该区域对多个进程都可见，即可用于进程间通信。</p>
<ul>
<li><p><strong>匿名管道</strong></p>
<p>匿名管道就是<strong>pipe</strong>，pipe只能在父子进程间通信，而且数据只能<strong>单向流动</strong>（半双工通信）。</p>
<p>使用方式：</p>
<ul>
<li>父进程创建管道，会得到两个文件描述符，分别指向管道的两端；</li>
<li>父进程创建子进程，从而子进程也有两个文件描述符指向同一管道；</li>
<li>父进程可写数据到管道，子进程就可从管道中读出数据，从而实现进程间通信，</li>
</ul>
</li>
</ul>
<p>使用关于管道的命令行：<code>ls | less</code>，该命令行的流向图如下：1：shell创建管道， 2：为ls创建一个进程，设置stdout为管理写端， 3：为less创建一个进程，设置stdin为管道读端</p>
<ul>
<li><strong>高级管道</strong></li>
</ul>
<p>​    通过popen将另一个程序当作一个新的进程在当前进程中启动，它算作当前进程的子进程，高级管道只能用在有亲缘关系的进程间通信，这种亲缘关系通常指父子进程。</p>
<ul>
<li><p><strong>命名管道</strong></p>
<p>匿名管道有个缺点就是通信的进程一定要有亲缘关系，而命名管道就不需要这种限制。命名管道其实就是一种特殊类型的文件，所谓的命名其实就是文件名，文件对各个进程都可见，通过命名管道创建好特殊文件后，就可以实现进程间通信。</p>
</li>
<li><p><strong>消息队列</strong></p>
<p>可以有多个进程向队列中写入数据，也可以有多个进程从队列里读出数据。消息队列中的每个消息可以赋予类型，从消息队列读消息时不一定要使用先进先出的顺序，可以按消息的类型读取，非指定类型的消息继续保留在队列中。本质上MessageQueue是存放在内核中的消息链表，每个消息队列链表会由消息队列标识符表示，这个消息队列存于内核中，只有主动的删除该消息队列或者内核重启时，消息队列才会被删除。</p>
<p><strong>消息队列VS命名管道</strong></p>
<ul>
<li>消息队列收发消息自动保证了同步，不需要由进程自己来提供同步方法，而命名管道需要自行处理同步问题；</li>
<li>消息队列接收数据可以根据消息类型有选择的接收特定类型的数据，不需要像命名管道一样默认接收数据。</li>
<li>消息队列有一个缺点就是发送和接收的每个数据都有最大长度的限制。</li>
</ul>
</li>
<li><p><strong>共享内存</strong></p>
<p>可开辟中一块内存，用于各个进程间共享，使得各个进程可以直接读写同一块内存空间，就像线程共享同一块地址空间一样，该方式基本上是最快的进程间通信方式，因为没有系统调用干预，也没有数据的拷贝操作，但由于共享同一块地址空间，数据竞争的问题就会出现，需要自己引入同步机制解决数据竞争问题。</p>
<p>共享内存只是一种方式，它的实现方式有很多种，主要的有mmap系统调用、Posix共享内存以及System V共享内存等。通过这三种“工具”共享地址空间后，通信的目的自然就会达到。</p>
</li>
<li><p><strong>信号</strong></p>
<p>信号也是进程间通信的一种方式，信号可以在任何时候发送给某一个进程，如果进程当前并未处于执行状态，内核将信号保存，直到进程恢复到执行态再发送给进程，进程可以对信号设置预处理方式，如果对信号设置了阻塞处理，则信号的传递会被延迟直到阻塞被取消，如果进程结束，那信号就被丢弃。我们常用的CTRL+C和kill等就是信号的一种，也达到了进程间通信的目的，进程也可以对信号设置signal捕获函数自定义处理逻辑。这种方式有很大的缺点：只有通知的作用，通知了一下消息的类型，但不能传输要交换的任何数据。</p>
</li>
</ul>
<p>​     Linux系统中常见的信号有：</p>
<p>​       SIGHUP：该信号在用户终端结束时发出，通常在中断的控制进程结束时，所有进程组都将收到该信号，该信号的默认操作是终止进程；</p>
<p>​       SIGINT：程序终止信号，通常的CTRL+C产生该信号来通知终止进程；</p>
<p>​       SIGQUIT：类似于程序错误信号，通常的CTRL+\产生该信号通知进程退出时产生core文件；</p>
<p>​       SIGILL：执行了非法指令，通常数据段或者堆栈溢出可能产生该信号；</p>
<p>​       SIGTRAP：供调试器使用，由断电指令或其它陷阱指令产生；</p>
<p>​       SIGABRT：使程序非正常结束，调用abort函数会产生该信号；</p>
<p>​       SIGBUS：非法地址，通常是地址对齐问题导致，比如访问一个4字节长的整数，但其地址不是4的倍数；</p>
<p>​       SIGSEGV：合理地址的非法访问，访问了未分配的内存或者没有权限的内存区域；</p>
<p>​       SIGPIPE：管道破裂信号，socket通信时经常会遇到，进程写入了一个无读者的管道；</p>
<p>​       SIGALRM：时钟定时信号，由alarm函数设置的时间终止时产生；</p>
<p>​       SIGFPE：出现浮点错误（比如除0操作）；</p>
<p>​       SIGKILL：杀死进程（不能被捕捉和忽略）；</p>
<ul>
<li><p><strong>信号量</strong></p>
<p>信号量就是一个特殊的变量，程序对其访问都是原子操作，每个信号量开始都有个初始值。最简单最常见的信号量是只能取0和1的变量，也叫二值信号量。</p>
<p>信号量有两个操作，P和V：</p>
</li>
</ul>
<p>​    P（down/wait）：如果信号量变量值大于0，则变量值减1，如果值为0，则阻塞进程；</p>
<p>​    V (up/signal)：如果有进程阻塞在该信号量上，则唤醒阻塞的进程，如果没有进程阻塞，则变量值加1</p>
<p>  信号量和信号没有任何关系，完全是不同的东西。</p>
<p>  互斥量用于<strong>互斥</strong>，信号量用于<strong>同步</strong>，互斥指的是某一资源同一时间只允许一个访问者访问，但无法限制访问顺序，访问是无序的，而同步在互斥的基础上可以控制访问者对资源的顺序。</p>
<ul>
<li><p><strong>套接字</strong>：</p>
</li>
<li><p><strong>文件</strong>：</p>
</li>
</ul>
<h3 id="JAVA中的NIO"><a href="#JAVA中的NIO" class="headerlink" title="JAVA中的NIO"></a>JAVA中的NIO</h3><p>JAVA BIO是面向流的，每次从流中读取一个或多个字节，直至读完，数据没有缓存在任何地方，也不能前后移动流中的数据，如果需要前后移动则需要额外将从流中读取到的数据缓存到一个缓存区。</p>
<p>JAVA NIO是面向缓存区的，数据直接读取/写入到一个缓存区，需要时可以在缓存区中前后移动，</p>
<p>JAVA BIO中流是阻塞的，当一个线程调用read() 或write()时，该线程被阻塞，直到有数据被读取或者数据写入。该线程在阻塞期间不能做其他事情。</p>
<p>JAVA NIO是非阻塞的，如果通道不可读/写，读写函数马上返回，而不会阻塞。线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程可以管理多个输入和输出通道（channel），即IO多路复用的原理。</p>
<p>JAVA BIO中调用操作系统提供的底层标准IO系统调用函数read()、write() ，此时调用此函数的进程（在JAVA中即java进程）由当前的用户态切换到内核态，然后OS的内核代码负责将相应的文件数据读取到内核的IO缓冲区，然后再把数据从内核IO缓冲区拷贝到进程的私有地址空间中去，这样便完成了一次IO操作。</p>
<p>JAVA NIO并不需要将数据拷贝到进程的私有地址空间中，而是直接将数据在内核IO缓冲区中的地址区域与进程的用户私有地址空间建立起映射关系，从而减少了一次CPU拷贝。</p>
<p>JAVA NIO主要由Channel、Buffer、Selector组成。数据只能从Channel读到Buffer，也只能将Buffer中的内容写入Channel。</p>
<p>JAVA NIO中的主要Channel实现：FileChannel(file)、DatagramChannel(UDP)、SocketChannel(TCP)、ServerSocketChannel(TCP)。通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。通常不会仅仅只监听一个连接,在while循环中调用 accept()方法.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//打开 ServerSocketChannel</span></span><br><span class="line">ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</span><br><span class="line">serverSocketChannel.socket().bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">9999</span>));</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    SocketChannel socketChannel = serverSocketChannel.accept();</span><br><span class="line">    <span class="comment">//do something with socketChannel...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//关闭ServerSocketChannel</span></span><br><span class="line">serverSocketChannel.close();</span><br></pre></td></tr></table></figure>



<p>Buffer本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。Buffer实现主要有：ByteBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer、ShortBuffer，分别对应基本数据类型：byte、short、int、long、float、double和char。</p>
<p>Selector允许单线程处理多个 Channel。首先向Selector注册Channel，然后调用Selector的select()方法，该方法会一直阻塞到某个注册的通道有事件就绪（有新连接进来，数据接收等）。一旦这个方法返回，线程就可以处理这些事件。</p>
<h3 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/iaIdQfEric9TyvNCUZ5V9vVVL9KicIukrtXUBfGpPL3Ngoe2os48MDXAu2FnGTQcdGFaqXRh6puSialDbX5SlPkSqw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<ul>
<li><p>需求分析阶段</p>
<p>  基本思想是用系统工程的思想和工程化得方法，根据用户至上的原则，自始自终按照结构化、模块化，自顶向下地对系统进行分析与设计。建立的主要步骤如下：</p>
<ol>
<li>首先画系统的输入输出，先画顶层数据流程图（DFD：Data Flow Diagram），顶层数据流程图只包含一个加工，用以表示被开发的系统，然后考虑该系统有哪些输入、输出数据流。</li>
<li>画系统内部，即画下层数据流层图。</li>
</ol>
</li>
<li><p>概念设计阶段</p>
<p>  对需求分析阶段的成果进行综合，归档以及抽象出一个独立具体的 DBMS 模型，与具体的 RDBMS 产品无关。</p>
<p>  在实际的开发中，常用 E-R（Entity-Relationship：实体关系）图来表示，常用的工具 PowerDesigner，可以实现 CDM（概念数据模型）-&gt;LDM（逻辑数据模型）-&gt;PDM（物理数据模型）-&gt;Database 的自动转换，这个过程称为<strong>正向工程</strong>，如果有 database 建库脚本，也可以通过 PowerDesigner 工具生成 CDM，即 Database-&gt;PDM-&gt;LDM-&gt;CDM，称为<strong>反向工程</strong>。</p>
<p>  概念设计通常采用自底向上，首先定义各系统局部的概念模型，然后再将他们集成合并起来，得到全局的概念模型。</p>
<p>  <strong>数据库设计三大范式</strong></p>
<ul>
<li>第一范式1NF：确保每个字段保持原子性，不可分割。</li>
<li>第二范式2NF：确保字段完全依赖于主键。</li>
<li>第三范式3NF：必须满足 2NF，实体中每个属性与主键直接相关而不能间接相关。</li>
</ul>
</li>
<li><p>逻辑设计阶段</p>
<p>  将概念数据模型转换为具体的 DBMS 所支持的数据模型，在此阶段，各子模块的 E-R 图之间的冲突主要有三类：属性冲突，命名冲突和结构冲突，同时 E-R 图向关系模型的转换，要解决如何将实体性和实体间的联系转换为关系模式，确定这些关系模式的属性和码，</p>
</li>
<li><p>数据库选型</p>
<p>  数据库方面主要包括数据存储，检索，安全，读写分离，分库分表，数据归档，接入数据仓库都要进行确认，根据业务的场景对相关的数据库产品进行调研比对，选择最适合业务场景的数据库作为存储。</p>
</li>
<li><p>物理设计阶段</p>
<p>  设计跟 RDBMS 相关的对象，例如设计存储过程，触发器，用户自定义函数，表空间等。</p>
</li>
<li><p>数据库实施阶段</p>
<p>  通过 PDM 生成数据库的建库脚本之后，需要进行规范性检查，通过之后就可以创建表结构。</p>
</li>
<li><p>数据库维护阶段</p>
<p>业务支撑：数据库版本变更、数据同步、数据归档、读写分离、分库分表等。</p>
<p>数据库运维：</p>
<p>  监控：基础资源（CPU\内存\IOPS\网络输入输出等）、数据库性能（TPS\QPS\缓存命中\主从延迟等）。</p>
<p>  告警：监控到异常指标时向维护人员发送警报。</p>
<p>  数据库备份、异地容灾、迁移升级（缩扩容、数据库软件版本等）、管理平台开发。</p>
<p><img src="%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0.assets/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%B4%E6%8A%A4.png" alt="图片"></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/03/24/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%AC%94%E8%AE%B0/" data-id="ckmn1nj9y000q9wa8hdbh1hne" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/03/24/JAVA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2021/03/24/%E7%AE%80%E5%8E%86-%E5%BE%90%E5%8D%9A/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/03/24/Python%20Cheatsheet/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/03/24/Python%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8C%85%E5%92%8C%E6%A8%A1%E5%9D%97/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/03/24/tofino-command/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/03/24/%E5%AE%89%E8%A3%85mininet%E5%92%8Ctofino-model/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/03/24/TNA%20model/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 xbo<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>